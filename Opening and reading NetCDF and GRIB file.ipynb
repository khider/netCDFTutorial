{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening and reading NetCDF and GRIB File\n",
    "\n",
    "## Table of Contents\n",
    "1. [What is the purpose of this Notebook](#purpose)\n",
    "2. [Example data](#data)\n",
    "3. [Opening and reading NetCDF files](#netcdf)  \n",
    "    3.1. [Package requirements](#packagenetCDF)  \n",
    "    3.2. [Opening and closing a NetCDF file](#opennetCDF)  \n",
    "    3.3. [Getting the list of attributes, dimensions, and variables](#dimensions)  \n",
    "    3.4. [Importing variables](#varnetCDF) \n",
    "4. [Opening and reading datasets across multiple NetCDF files](#MFnetcdf)\n",
    "    4.1. [Package requirements](#packageMFnetcdf)\n",
    "    4.2. [Opening multiple NetCDF files](#opennetcdfs)\n",
    "    4.3. [Printing the list of attributes, dimensions, and variables](#MFdimensions)\n",
    "    4.4. [Importing Variables](#varnetCDFs)\n",
    "5. [Opening and reading GRIB files](#GRIB)  \n",
    "    5.1. [Package requirements](#packageGRIB)  \n",
    "    5.2. [Opening a GRIB file](#openGRIB)  \n",
    "    5.3. [Getting the list of variables and associated properties](#properties) \n",
    "    5.4. [Importing variables](#varGRIB)\n",
    "\n",
    "## <a name=\"purpose\"> What is the purpose of this Notebook?</a>\n",
    "\n",
    "This interactive Jupyter Notebook guides the reader through the steps of opening, reading, and importing variables from a file in the NetCDF or GRIB format.  \n",
    "\n",
    "To know more about NetCDF, visit [https://www.unidata.ucar.edu/software/netcdf/](https://www.unidata.ucar.edu/software/netcdf/).  \n",
    "To know more about GRIB, visit [https://www.wmo.int/pages/prog/www/WDM/Guides/Guide-binary-2.html](https://www.wmo.int/pages/prog/www/WDM/Guides/Guide-binary-2.html).\n",
    "\n",
    "## <a name=\"data\"> Example data</a>\n",
    "\n",
    "This Notebook makes use of the same dataset downloaded in both the NetCDF and GRIB format. Please note that the data is originally in GRIB format and transformed upon download.  \n",
    "\n",
    "The data consists of monthly (obtained from daily means) Total Precipitation for the year 2010 obtained from ECMWF ERA-20CM. The data can be downloaded [here](http://apps.ecmwf.int/datasets/data/era20cm-edmo/levtype=sfc/?month_years=2010&number=0&param=228.128) (Using ensemble 0). The two files are included in the folder containing this Notebook.\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p>**NOTE**</p>\n",
    "<p> You need to register to access these data from the ECMWF portal</p>\n",
    "</div>  \n",
    "\n",
    " \n",
    "\n",
    "## <a name=\"netcdf\"> Opening and reading NetCDF files </a>\n",
    "### <a name=\"packagenetCDF\"> Package requirements </a>\n",
    "\n",
    "This example makes use of the [netCDF4 Python package](https://github.com/Unidata/netcdf4-python), which is available through Pypi: `pip install netcdf4`\n",
    "\n",
    "For a single dataset, use the module `Dataset`.\n",
    "\n",
    "### <a name=\"opennetCDF\"> Opening and closing a NetCDF file </a>\n",
    "\n",
    "To create a netCDF file from python, you simply call the Dataset constructor. This is also the method used to open an existing netCDF file. If the file is open for write access (**mode='w', 'r+' or 'a'**), you may write any type of data including new dimensions, groups, variables and attributes. netCDF files come in five flavors (**NETCDF3_CLASSIC**, **NETCDF3_64BIT_OFFSET**, **NETCDF3_64BIT_DATA**, **NETCDF4_CLASSIC**, and **NETCDF4**). **NETCDF3_CLASSIC** was the original netcdf binary format, and was limited to file sizes less than 2 Gb. **NETCDF3_64BIT_OFFSET** was introduced in version 3.6.0 of the library, and extended the original binary format to allow for file sizes greater than 2 Gb. **NETCDF3_64BIT_DATA** is a new format that requires version 4.4.0 of the C library - it extends the **NETCDF3_64BIT_OFFSET** binary format to allow for unsigned/64 bit integer data types and 64-bit dimension sizes. **NETCDF3_64BIT** is an alias for **NETCDF3_64BIT_OFFSET**. **NETCDF4_CLASSIC** files use the version 4 disk format (HDF5), but omits features not found in the version 3 API. They can be read by netCDF 3 clients only if they have been relinked against the netCDF 4 library. They can also be read by HDF5 clients. **NETCDF4** files use the version 4 disk format (HDF5) and use the new features of the version 4 API. The **netCDF4** module can read and write files in any of these formats. When creating a new file, the format may be specified using the format keyword in the Dataset constructor. The default format is **NETCDF4**. To see how a given file is formatted, you can examine the data_model attribute. Closing the netCDF file is accomplished via the close method of the Dataset instance. ([source](http://unidata.github.io/netcdf4-python/#section1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF3_64BIT_OFFSET\n"
     ]
    }
   ],
   "source": [
    "# Open a dataset\n",
    "from netCDF4 import Dataset\n",
    "dataset = Dataset(\"/Volumes/Data HD/Documents/MINT/Climate/netCDFTutorial/test.nc\")\n",
    "print(dataset.data_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typing `dataset` will give you an overview of what's in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF3_64BIT_OFFSET data model, file format NETCDF3):\n",
       "    Conventions: CF-1.6\n",
       "    history: 2018-02-26 22:26:35 GMT by grib_to_netcdf-2.6.0: grib_to_netcdf /data/data01/scratch/_mars-atls18-a562cefde8a29a7288fa0b8b7f9413f7-u5uxdA.grib -o /data/data02/scratch/_grib2netcdf-atls00-a82bacafb5c306db76464bc7e824bb75-DDcsCC.nc -utime\n",
       "    dimensions(sizes): longitude(320), latitude(161), time(12)\n",
       "    variables(dimensions): float32 \u001b[4mlongitude\u001b[0m(longitude), float32 \u001b[4mlatitude\u001b[0m(latitude), int32 \u001b[4mtime\u001b[0m(time), int16 \u001b[4mtp\u001b[0m(time,latitude,longitude)\n",
       "    groups: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close a dataset\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name='dimensions'> Getting the list of attributes, dimensions, and variables </a>\n",
    "\n",
    "The following function has been updated to Python 3.5 ([source](http://schubert.atmos.colostate.edu/~cslocum/netcdf_example.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt  # Python standard library datetime  module\n",
    "import numpy as np\n",
    "\n",
    "def ncdump(nc_fid, verb=True):\n",
    "    '''\n",
    "    ncdump outputs dimensions, variables and their attribute information.\n",
    "    The information is similar to that of NCAR's ncdump utility.\n",
    "    ncdump requires a valid instance of Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_fid : netCDF4.Dataset\n",
    "        A netCDF4 dateset object\n",
    "    verb : Boolean\n",
    "        whether or not nc_attrs, nc_dims, and nc_vars are printed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nc_attrs : list\n",
    "        A Python list of the NetCDF file global attributes\n",
    "    nc_dims : list\n",
    "        A Python list of the NetCDF file dimensions\n",
    "    nc_vars : list\n",
    "        A Python list of the NetCDF file variables\n",
    "    '''\n",
    "    def print_ncattr(key):\n",
    "        \"\"\"\n",
    "        Prints the NetCDF file attributes for a given key\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key : unicode\n",
    "            a valid netCDF4.Dataset.variables key\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"\\t\\ttype:\", repr(nc_fid.variables[key].dtype))\n",
    "            for ncattr in nc_fid.variables[key].ncattrs():\n",
    "                print('\\t\\t%s:' % ncattr,\\\n",
    "                      repr(nc_fid.variables[key].getncattr(ncattr)))\n",
    "        except KeyError:\n",
    "            print(\"\\t\\tWARNING: %s does not contain variable attributes\" % key)\n",
    "\n",
    "    # NetCDF global attributes\n",
    "    nc_attrs = nc_fid.ncattrs()\n",
    "    if verb:\n",
    "        print(\"NetCDF Global Attributes:\")\n",
    "        for nc_attr in nc_attrs:\n",
    "            print('\\t%s:' % nc_attr, repr(nc_fid.getncattr(nc_attr)))\n",
    "    nc_dims = [dim for dim in nc_fid.dimensions]  # list of nc dimensions\n",
    "    # Dimension shape information.\n",
    "    if verb:\n",
    "        print(\"NetCDF dimension information:\")\n",
    "        for dim in nc_dims:\n",
    "            print(\"\\tName:\", dim) \n",
    "            print(\"\\t\\tsize:\", len(nc_fid.dimensions[dim]))\n",
    "            print_ncattr(dim)\n",
    "    # Variable information.\n",
    "    nc_vars = [var for var in nc_fid.variables]  # list of nc variables\n",
    "    if verb:\n",
    "        print(\"NetCDF variable information:\")\n",
    "        for var in nc_vars:\n",
    "            if var not in nc_dims:\n",
    "                print('\\tName:', var)\n",
    "                print(\"\\t\\tdimensions:\", nc_fid.variables[var].dimensions)\n",
    "                print(\"\\t\\tsize:\", nc_fid.variables[var].size)\n",
    "                print_ncattr(var)\n",
    "    return nc_attrs, nc_dims, nc_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the attributes, dimensions and variables contained in the netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF Global Attributes:\n",
      "\tConventions: 'CF-1.6'\n",
      "\thistory: '2018-02-26 22:26:35 GMT by grib_to_netcdf-2.6.0: grib_to_netcdf /data/data01/scratch/_mars-atls18-a562cefde8a29a7288fa0b8b7f9413f7-u5uxdA.grib -o /data/data02/scratch/_grib2netcdf-atls00-a82bacafb5c306db76464bc7e824bb75-DDcsCC.nc -utime'\n",
      "NetCDF dimension information:\n",
      "\tName: longitude\n",
      "\t\tsize: 320\n",
      "\t\ttype: dtype('float32')\n",
      "\t\tunits: 'degrees_east'\n",
      "\t\tlong_name: 'longitude'\n",
      "\tName: latitude\n",
      "\t\tsize: 161\n",
      "\t\ttype: dtype('float32')\n",
      "\t\tunits: 'degrees_north'\n",
      "\t\tlong_name: 'latitude'\n",
      "\tName: time\n",
      "\t\tsize: 12\n",
      "\t\ttype: dtype('int32')\n",
      "\t\tunits: 'hours since 1900-01-01 00:00:0.0'\n",
      "\t\tlong_name: 'time'\n",
      "\t\tcalendar: 'gregorian'\n",
      "NetCDF variable information:\n",
      "\tName: tp\n",
      "\t\tdimensions: ('time', 'latitude', 'longitude')\n",
      "\t\tsize: 618240\n",
      "\t\ttype: dtype('int16')\n",
      "\t\tscale_factor: 6.624043998318357e-07\n",
      "\t\tadd_offset: 0.021704342564889928\n",
      "\t\t_FillValue: -32767\n",
      "\t\tmissing_value: -32767\n",
      "\t\tunits: 'm'\n",
      "\t\tlong_name: 'Total precipitation'\n"
     ]
    }
   ],
   "source": [
    "dataset_attrs, dataset_dims, dataset_vars = ncdump(dataset, verb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global attibutes tells us that the name of the variables follow the CF (Climate and Forecast) metadata conventions, which have been mapped to the GSN ontology. \n",
    "\n",
    "To learn more about the CF convention: [http://cfconventions.org](http://cfconventions.org)\n",
    "\n",
    "The CF standard Name Table can be viewed here: [http://cfconventions.org/Data/cf-standard-names/49/build/cf-standard-name-table.html](http://cfconventions.org/Data/cf-standard-names/49/build/cf-standard-name-table.html)\n",
    "\n",
    "We need to build a function that looks for the standard_name automatically and matches to the GSN name. If the standard_name is not available, we will need a mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a name='varnetCDF'> Importing Variables </a>\n",
    "\n",
    "The following function automatically opens a file with the netCDF extension, searches the long name against a list of key variables chosen by the user or a computer, and returns the values into a dictionary with keys as long names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNcVar(nc_file, keys):\n",
    "    ''' Extract variables from a netCDF file.\n",
    "    \n",
    "    This function gets the variable contained in a netCDF file \n",
    "    and return them into Python nested dictionaries. The first\n",
    "    dictionary's key contains the longname, while the\n",
    "    second dictionary contains values, standard name (CF),\n",
    "    units and the missing data flag.\n",
    "    \n",
    "    Args:\n",
    "        nc_file (str): A name (path) of a netCDF file\n",
    "        keys (list): A list of keys to fetch the variables according\n",
    "            to the CF standard\n",
    "    \n",
    "    Returns:\n",
    "        dict_out (dict): A dictionary containing the standard names as keys and\n",
    "            the associated data as values.\n",
    "    '''\n",
    "    from netCDF4 import Dataset\n",
    "    #Open the netCDF file\n",
    "    nc_fid = Dataset(nc_file)\n",
    "    # Get the variable names\n",
    "    nc_vars = [var for var in nc_fid.variables]\n",
    "    # Get the longnames for each variables\n",
    "    nc_vars_longname = []\n",
    "    #Get the units\n",
    "    nc_vars_units =[]\n",
    "    # Get the standard name\n",
    "    nc_vars_standardname=[]\n",
    "    #Add corrections if needed\n",
    "    nc_vars_scale_factor=[]\n",
    "    nc_vars_add_offset=[]\n",
    "    # Check the missing value tags\n",
    "    nc_vars_missing_value=[]\n",
    "    \n",
    "    for vars in nc_vars:\n",
    "        if 'long_name' in nc_fid.variables[vars].ncattrs():\n",
    "            nc_vars_longname.append(nc_fid.variables[vars].getncattr('long_name'))\n",
    "        else:\n",
    "            nc_vars_longname.append(vars)\n",
    "        if 'units' in nc_fid.variables[vars].ncattrs():\n",
    "            nc_vars_units.append(nc_fid.variables[vars].getncattr('units'))\n",
    "        else:\n",
    "            nc_vars_units.append('NA')\n",
    "        if 'standard_name' in nc_fid.variables[vars].ncattrs():\n",
    "            nc_vars_standardname.append(nc_fid.variables[vars].getncattr('standard_name'))\n",
    "        else:\n",
    "            nc_vars_standardname.append('NA')    \n",
    "        if 'scale_factor' in nc_fid.variables[vars].ncattrs():\n",
    "            nc_vars_scale_factor.append(nc_fid.variables[vars].getncattr('scale_factor'))\n",
    "        else:\n",
    "            nc_vars_scale_factor.append(1)\n",
    "        if 'add_offset' in nc_fid.variables[vars].ncattrs():\n",
    "            nc_vars_add_offset.append(nc_fid.variables[vars].getncattr('add_offset'))\n",
    "        else:\n",
    "            nc_vars_add_offset.append(0) \n",
    "        if 'missing_value' in nc_fid.variables[vars].ncattrs(): \n",
    "            nc_vars_missing_value.append(nc_fid.variables[vars].getncattr('missing_value'))\n",
    "        else:\n",
    "            nc_vars_missing_value.append('NA')\n",
    "    # Check for the list against the desired variables and output.\n",
    "    dict_out ={}\n",
    "    for name in nc_vars_longname:\n",
    "        if name in keys:\n",
    "            f = {'values':[],'units':[],'missing_value':[],'standard_name':{}}\n",
    "            idx = nc_vars_longname.index(name)\n",
    "            f['values']=(nc_fid.variables[nc_vars[idx]][:]*nc_vars_scale_factor[idx])\\\n",
    "                +nc_vars_add_offset[idx]\n",
    "            f['units']=nc_vars_units[idx]\n",
    "            f['missing_value'] = nc_vars_missing_value[idx]\n",
    "            f['standard_name'] = nc_vars_standardname[idx]\n",
    "            dict_out[name] = f\n",
    "               \n",
    "    return dict_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total precipitation': {'missing_value': -32767,\n",
       "  'standard_name': 'NA',\n",
       "  'units': 'm',\n",
       "  'values': array([[[0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          ...,\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434]],\n",
       "  \n",
       "         [[0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          ...,\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434]],\n",
       "  \n",
       "         [[0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          ...,\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          ...,\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434]],\n",
       "  \n",
       "         [[0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          ...,\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434]],\n",
       "  \n",
       "         [[0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          ...,\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434],\n",
       "          [0.02170434, 0.02170434, 0.02170434, ..., 0.02170434,\n",
       "           0.02170434, 0.02170434]]])},\n",
       " 'latitude': {'missing_value': 'NA',\n",
       "  'standard_name': 'NA',\n",
       "  'units': 'degrees_north',\n",
       "  'values': array([ 90.   ,  88.875,  87.75 ,  86.625,  85.5  ,  84.375,  83.25 ,\n",
       "          82.125,  81.   ,  79.875,  78.75 ,  77.625,  76.5  ,  75.375,\n",
       "          74.25 ,  73.125,  72.   ,  70.875,  69.75 ,  68.625,  67.5  ,\n",
       "          66.375,  65.25 ,  64.125,  63.   ,  61.875,  60.75 ,  59.625,\n",
       "          58.5  ,  57.375,  56.25 ,  55.125,  54.   ,  52.875,  51.75 ,\n",
       "          50.625,  49.5  ,  48.375,  47.25 ,  46.125,  45.   ,  43.875,\n",
       "          42.75 ,  41.625,  40.5  ,  39.375,  38.25 ,  37.125,  36.   ,\n",
       "          34.875,  33.75 ,  32.625,  31.5  ,  30.375,  29.25 ,  28.125,\n",
       "          27.   ,  25.875,  24.75 ,  23.625,  22.5  ,  21.375,  20.25 ,\n",
       "          19.125,  18.   ,  16.875,  15.75 ,  14.625,  13.5  ,  12.375,\n",
       "          11.25 ,  10.125,   9.   ,   7.875,   6.75 ,   5.625,   4.5  ,\n",
       "           3.375,   2.25 ,   1.125,   0.   ,  -1.125,  -2.25 ,  -3.375,\n",
       "          -4.5  ,  -5.625,  -6.75 ,  -7.875,  -9.   , -10.125, -11.25 ,\n",
       "         -12.375, -13.5  , -14.625, -15.75 , -16.875, -18.   , -19.125,\n",
       "         -20.25 , -21.375, -22.5  , -23.625, -24.75 , -25.875, -27.   ,\n",
       "         -28.125, -29.25 , -30.375, -31.5  , -32.625, -33.75 , -34.875,\n",
       "         -36.   , -37.125, -38.25 , -39.375, -40.5  , -41.625, -42.75 ,\n",
       "         -43.875, -45.   , -46.125, -47.25 , -48.375, -49.5  , -50.625,\n",
       "         -51.75 , -52.875, -54.   , -55.125, -56.25 , -57.375, -58.5  ,\n",
       "         -59.625, -60.75 , -61.875, -63.   , -64.125, -65.25 , -66.375,\n",
       "         -67.5  , -68.625, -69.75 , -70.875, -72.   , -73.125, -74.25 ,\n",
       "         -75.375, -76.5  , -77.625, -78.75 , -79.875, -81.   , -82.125,\n",
       "         -83.25 , -84.375, -85.5  , -86.625, -87.75 , -88.875, -90.   ],\n",
       "        dtype=float32)},\n",
       " 'longitude': {'missing_value': 'NA',\n",
       "  'standard_name': 'NA',\n",
       "  'units': 'degrees_east',\n",
       "  'values': array([  0.   ,   1.125,   2.25 ,   3.375,   4.5  ,   5.625,   6.75 ,\n",
       "           7.875,   9.   ,  10.125,  11.25 ,  12.375,  13.5  ,  14.625,\n",
       "          15.75 ,  16.875,  18.   ,  19.125,  20.25 ,  21.375,  22.5  ,\n",
       "          23.625,  24.75 ,  25.875,  27.   ,  28.125,  29.25 ,  30.375,\n",
       "          31.5  ,  32.625,  33.75 ,  34.875,  36.   ,  37.125,  38.25 ,\n",
       "          39.375,  40.5  ,  41.625,  42.75 ,  43.875,  45.   ,  46.125,\n",
       "          47.25 ,  48.375,  49.5  ,  50.625,  51.75 ,  52.875,  54.   ,\n",
       "          55.125,  56.25 ,  57.375,  58.5  ,  59.625,  60.75 ,  61.875,\n",
       "          63.   ,  64.125,  65.25 ,  66.375,  67.5  ,  68.625,  69.75 ,\n",
       "          70.875,  72.   ,  73.125,  74.25 ,  75.375,  76.5  ,  77.625,\n",
       "          78.75 ,  79.875,  81.   ,  82.125,  83.25 ,  84.375,  85.5  ,\n",
       "          86.625,  87.75 ,  88.875,  90.   ,  91.125,  92.25 ,  93.375,\n",
       "          94.5  ,  95.625,  96.75 ,  97.875,  99.   , 100.125, 101.25 ,\n",
       "         102.375, 103.5  , 104.625, 105.75 , 106.875, 108.   , 109.125,\n",
       "         110.25 , 111.375, 112.5  , 113.625, 114.75 , 115.875, 117.   ,\n",
       "         118.125, 119.25 , 120.375, 121.5  , 122.625, 123.75 , 124.875,\n",
       "         126.   , 127.125, 128.25 , 129.375, 130.5  , 131.625, 132.75 ,\n",
       "         133.875, 135.   , 136.125, 137.25 , 138.375, 139.5  , 140.625,\n",
       "         141.75 , 142.875, 144.   , 145.125, 146.25 , 147.375, 148.5  ,\n",
       "         149.625, 150.75 , 151.875, 153.   , 154.125, 155.25 , 156.375,\n",
       "         157.5  , 158.625, 159.75 , 160.875, 162.   , 163.125, 164.25 ,\n",
       "         165.375, 166.5  , 167.625, 168.75 , 169.875, 171.   , 172.125,\n",
       "         173.25 , 174.375, 175.5  , 176.625, 177.75 , 178.875, 180.   ,\n",
       "         181.125, 182.25 , 183.375, 184.5  , 185.625, 186.75 , 187.875,\n",
       "         189.   , 190.125, 191.25 , 192.375, 193.5  , 194.625, 195.75 ,\n",
       "         196.875, 198.   , 199.125, 200.25 , 201.375, 202.5  , 203.625,\n",
       "         204.75 , 205.875, 207.   , 208.125, 209.25 , 210.375, 211.5  ,\n",
       "         212.625, 213.75 , 214.875, 216.   , 217.125, 218.25 , 219.375,\n",
       "         220.5  , 221.625, 222.75 , 223.875, 225.   , 226.125, 227.25 ,\n",
       "         228.375, 229.5  , 230.625, 231.75 , 232.875, 234.   , 235.125,\n",
       "         236.25 , 237.375, 238.5  , 239.625, 240.75 , 241.875, 243.   ,\n",
       "         244.125, 245.25 , 246.375, 247.5  , 248.625, 249.75 , 250.875,\n",
       "         252.   , 253.125, 254.25 , 255.375, 256.5  , 257.625, 258.75 ,\n",
       "         259.875, 261.   , 262.125, 263.25 , 264.375, 265.5  , 266.625,\n",
       "         267.75 , 268.875, 270.   , 271.125, 272.25 , 273.375, 274.5  ,\n",
       "         275.625, 276.75 , 277.875, 279.   , 280.125, 281.25 , 282.375,\n",
       "         283.5  , 284.625, 285.75 , 286.875, 288.   , 289.125, 290.25 ,\n",
       "         291.375, 292.5  , 293.625, 294.75 , 295.875, 297.   , 298.125,\n",
       "         299.25 , 300.375, 301.5  , 302.625, 303.75 , 304.875, 306.   ,\n",
       "         307.125, 308.25 , 309.375, 310.5  , 311.625, 312.75 , 313.875,\n",
       "         315.   , 316.125, 317.25 , 318.375, 319.5  , 320.625, 321.75 ,\n",
       "         322.875, 324.   , 325.125, 326.25 , 327.375, 328.5  , 329.625,\n",
       "         330.75 , 331.875, 333.   , 334.125, 335.25 , 336.375, 337.5  ,\n",
       "         338.625, 339.75 , 340.875, 342.   , 343.125, 344.25 , 345.375,\n",
       "         346.5  , 347.625, 348.75 , 349.875, 351.   , 352.125, 353.25 ,\n",
       "         354.375, 355.5  , 356.625, 357.75 , 358.875], dtype=float32)},\n",
       " 'time': {'missing_value': 'NA',\n",
       "  'standard_name': 'NA',\n",
       "  'units': 'hours since 1900-01-01 00:00:0.0',\n",
       "  'values': array([964248, 964992, 965664, 966408, 967128, 967872, 968592, 969336,\n",
       "         970080, 970800, 971544, 972264], dtype=int32)}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_file = \"/Volumes/Data HD/Documents/MINT/Climate/netCDFTutorial/test.nc\"\n",
    "keys = ['latitude','longitude','time','Total precipitation'] \n",
    "\n",
    "dict_out = getNcVar(nc_file, keys)\n",
    "\n",
    "dict_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='MFnetcdf'>Opening and reading datasets across multiple NetCDF files</a>\n",
    "\n",
    "### <a name='packageMFnetcdf'> Package requirements </a>\n",
    "\n",
    "This example makes use of the netCDF4 Python package, which is available through Pypi: pip install netcdf4\n",
    "\n",
    "For a dataset spanning multiple NetCDF files, use the package `MFDataset`.\n",
    "\n",
    "### <a name='opennetcdfs'> Opening multiple NetCDF files </a>\n",
    "\n",
    "If you want to read data from a variable that spans multiple netCDF files, you can use the `MFDataset` class to read the data as if it were contained in a single file. Instead of using a single filename to create a `Dataset` instance, create a `MFDataset` instance with either a list of filenames, or a string with a wildcard (which is then converted to a sorted list of files using the python glob module). Variables in the list of files that share the same unlimited dimension are aggregated together, and can be sliced across multiple files. To illustrate this, let's first create a bunch of netCDF files with the same variable (with the same unlimited dimension). The files must in be in **NETCDF3_64BIT_OFFSET**, **NETCDF3_64BIT_DATA**, **NETCDF3_CLASSIC** or **NETCDF4_CLASSIC** format (**NETCDF4** formatted multi-file datasets are not supported)(source)(#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.MFDataset'>\n",
       "root group (NETCDF3_64BIT_OFFSET data model, file format NETCDF3):\n",
       "    Conventions: CF-1.6\n",
       "    history: 2018-03-16 21:28:54 GMT by grib_to_netcdf-2.6.0: grib_to_netcdf /data/data02/scratch/_mars-atls04-a82bacafb5c306db76464bc7e824bb75-Fev7A1.grib -o /data/data02/scratch/_grib2netcdf-atls13-a82bacafb5c306db76464bc7e824bb75-9RHCwe.nc -utime\n",
       "    dimensions = ('longitude', 'latitude', 'time')\n",
       "    variables = ('longitude', 'latitude', 'time', 'sp', 'tcc', 'u10', 'v10', 't2m', 'd2m', 'al', 'tp', 'skt', 'fsr')\n",
       "    groups = ()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from netCDF4 import MFDataset\n",
    "# Just get a list of netCDF files. \n",
    "root = \"/Volumes/Data HD/Documents/MINT/Climate/netCDFTutorial\"\n",
    "files = [\"Oct2010.nc\",\"Nov2010.nc\",\"Dec2010.nc\"]\n",
    "\n",
    "file_names =[]\n",
    "for name in files:\n",
    "    file_names.append(root+\"/\"+name)\n",
    "    \n",
    "#Open the file and get the keys for this example\n",
    "nc_fid = MFDataset(file_names)\n",
    "\n",
    "nc_fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name='MFdimensions'> Printing the list of attributes, dimensions and variables </a>\n",
    "\n",
    "The function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <a name='GRIB'> Opening and reading GRIB files </a>\n",
    "\n",
    "### <a name='packageGRIB'> Package requirement </a>\n",
    "\n",
    "This example makes use of the [pygrib](https://github.com/jswhit/pygrib), which is available through conda: `conda install -c conda-forge pygrib`\n",
    "\n",
    "### <a name = 'openGRIB'> Opening a GRIB file </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pygrib\n",
    "\n",
    "file = \"/Volumes/Data HD/Documents/MINT/Climate/netCDFTutorial/test.grib\"\n",
    "\n",
    "grbs = pygrib.open(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name='properties'> Getting the list of variables and associated properties </a>\n",
    "\n",
    "The variables `grbs` from above contain information at each time step. Therefore, one needs to iterate over `grbs` to get the values and other associated properties at each time step.\n",
    "\n",
    "For instance, let's take the first value packed in grbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1:Total precipitation:m (avgfc):reduced_gg:surface:level 0:fcst time 3 hrs (avgfc):from 201001010000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grb = grbs[1]\n",
    "\n",
    "grb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know the available metadata associated with each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parametersVersion',\n",
       " 'UseEcmfConventions',\n",
       " 'GRIBEX_boustrophedonic',\n",
       " 'hundred',\n",
       " 'globalDomain',\n",
       " 'GRIBEditionNumber',\n",
       " 'eps',\n",
       " 'offsetSection0',\n",
       " 'section0Length',\n",
       " 'totalLength',\n",
       " 'editionNumber',\n",
       " 'WMO',\n",
       " 'productionStatusOfProcessedData',\n",
       " 'section1Length',\n",
       " 'wrongPadding',\n",
       " 'table2Version',\n",
       " 'centre',\n",
       " 'centreDescription',\n",
       " 'generatingProcessIdentifier',\n",
       " 'gridDefinition',\n",
       " 'indicatorOfParameter',\n",
       " 'parameterName',\n",
       " 'parameterUnits',\n",
       " 'indicatorOfTypeOfLevel',\n",
       " 'pressureUnits',\n",
       " 'typeOfLevelECMF',\n",
       " 'typeOfLevel',\n",
       " 'level',\n",
       " 'yearOfCentury',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'minute',\n",
       " 'second',\n",
       " 'unitOfTimeRange',\n",
       " 'P1',\n",
       " 'P2',\n",
       " 'timeRangeIndicator',\n",
       " 'numberIncludedInAverage',\n",
       " 'numberMissingFromAveragesOrAccumulations',\n",
       " 'centuryOfReferenceTimeOfData',\n",
       " 'subCentre',\n",
       " 'paramIdECMF',\n",
       " 'paramId',\n",
       " 'cfNameECMF',\n",
       " 'cfName',\n",
       " 'cfVarNameECMF',\n",
       " 'cfVarName',\n",
       " 'unitsECMF',\n",
       " 'units',\n",
       " 'nameECMF',\n",
       " 'name',\n",
       " 'decimalScaleFactor',\n",
       " 'setLocalDefinition',\n",
       " 'dataDate',\n",
       " 'year',\n",
       " 'dataTime',\n",
       " 'julianDay',\n",
       " 'stepUnits',\n",
       " 'stepType',\n",
       " 'stepRange',\n",
       " 'startStep',\n",
       " 'endStep',\n",
       " 'marsParam',\n",
       " 'validityDate',\n",
       " 'validityTime',\n",
       " 'deleteLocalDefinition',\n",
       " 'localUsePresent',\n",
       " 'localDefinitionNumber',\n",
       " 'GRIBEXSection1Problem',\n",
       " 'marsClass',\n",
       " 'marsType',\n",
       " 'marsStream',\n",
       " 'experimentVersionNumber',\n",
       " 'perturbationNumber',\n",
       " 'numberOfForecastsInEnsemble',\n",
       " 'grib2LocalSectionNumber',\n",
       " 'verificationDate',\n",
       " 'monthlyVerificationDate',\n",
       " 'shortNameECMF',\n",
       " 'shortName',\n",
       " 'ifsParam',\n",
       " 'gridDescriptionSectionPresent',\n",
       " 'bitmapPresent',\n",
       " 'angularPrecision',\n",
       " 'section2Length',\n",
       " 'radius',\n",
       " 'numberOfVerticalCoordinateValues',\n",
       " 'neitherPresent',\n",
       " 'pvlLocation',\n",
       " 'dataRepresentationType',\n",
       " 'gridDefinitionDescription',\n",
       " 'gridDefinitionTemplateNumber',\n",
       " 'Ni',\n",
       " 'Nj',\n",
       " 'latitudeOfFirstGridPoint',\n",
       " 'latitudeOfFirstGridPointInDegrees',\n",
       " 'longitudeOfFirstGridPoint',\n",
       " 'longitudeOfFirstGridPointInDegrees',\n",
       " 'resolutionAndComponentFlags',\n",
       " 'ijDirectionIncrementGiven',\n",
       " 'earthIsOblate',\n",
       " 'resolutionAndComponentFlags3',\n",
       " 'resolutionAndComponentFlags4',\n",
       " 'uvRelativeToGrid',\n",
       " 'resolutionAndComponentFlags6',\n",
       " 'resolutionAndComponentFlags7',\n",
       " 'resolutionAndComponentFlags8',\n",
       " 'latitudeOfLastGridPoint',\n",
       " 'latitudeOfLastGridPointInDegrees',\n",
       " 'longitudeOfLastGridPoint',\n",
       " 'longitudeOfLastGridPointInDegrees',\n",
       " 'iDirectionIncrement',\n",
       " 'iDirectionIncrementInDegrees',\n",
       " 'N',\n",
       " 'scanningMode',\n",
       " 'iScansNegatively',\n",
       " 'jScansPositively',\n",
       " 'jPointsAreConsecutive',\n",
       " 'alternativeRowScanning',\n",
       " 'iScansPositively',\n",
       " 'scanningMode4',\n",
       " 'scanningMode5',\n",
       " 'scanningMode6',\n",
       " 'scanningMode7',\n",
       " 'scanningMode8',\n",
       " 'global',\n",
       " 'numberOfDataPoints',\n",
       " 'numberOfValues',\n",
       " 'latLonValues',\n",
       " 'latitudes',\n",
       " 'longitudes',\n",
       " 'distinctLatitudes',\n",
       " 'distinctLongitudes',\n",
       " 'isOctahedral',\n",
       " 'gaussianGridName',\n",
       " 'PVPresent',\n",
       " 'PLPresent',\n",
       " 'numberOfOctectsForNumberOfPoints',\n",
       " 'interpretationOfNumberOfPoints',\n",
       " 'pl',\n",
       " 'deletePV',\n",
       " 'lengthOfHeaders',\n",
       " 'missingValue',\n",
       " 'tableReference',\n",
       " 'section4Length',\n",
       " 'halfByte',\n",
       " 'dataFlag',\n",
       " 'binaryScaleFactor',\n",
       " 'referenceValue',\n",
       " 'referenceValueError',\n",
       " 'sphericalHarmonics',\n",
       " 'complexPacking',\n",
       " 'integerPointValues',\n",
       " 'additionalFlagPresent',\n",
       " 'orderOfSPD',\n",
       " 'boustrophedonic',\n",
       " 'hideThis',\n",
       " 'packingType',\n",
       " 'bitsPerValue',\n",
       " 'constantFieldHalfByte',\n",
       " 'bitMapIndicator',\n",
       " 'values',\n",
       " 'numberOfCodedValues',\n",
       " 'packingError',\n",
       " 'unpackedError',\n",
       " 'maximum',\n",
       " 'minimum',\n",
       " 'average',\n",
       " 'numberOfMissing',\n",
       " 'standardDeviation',\n",
       " 'skewness',\n",
       " 'kurtosis',\n",
       " 'isConstant',\n",
       " 'dataLength',\n",
       " 'changeDecimalPrecision',\n",
       " 'decimalPrecision',\n",
       " 'bitsPerValueAndRepack',\n",
       " 'scaleValuesBy',\n",
       " 'offsetValuesBy',\n",
       " 'gridType',\n",
       " 'getNumberOfValues',\n",
       " 'section5Length',\n",
       " 'analDate',\n",
       " 'validDate']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grb.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name='varGRIB'> Importing variables </a>\n",
    "\n",
    "This function opens a file with a GRIB extension and places all the values for the variables into a dictionary that can then be exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getGribVar(grib_file, keys):\n",
    "    ''' Extract variables from a GRIB file.\n",
    "    \n",
    "    This function gets the variable contained in a GRIB file \n",
    "    and return them into Python nested dictionaries. The first\n",
    "    dictionary's key contains the longname, while the\n",
    "    second dictionary contains values, the standard CF name,\n",
    "    units and the missing data flag.\n",
    "    \n",
    "    Args:\n",
    "        grib_file (str): A name (path) of a GRIB file\n",
    "        keys (list): A list of keys to fetch the variables according\n",
    "            to the CF standard\n",
    "    \n",
    "    Returns:\n",
    "        dict_out (dict): A dictionary containing the standard names as keys and\n",
    "            the associated data as values.\n",
    "    '''\n",
    "    import pygrib    \n",
    "    \n",
    "    grbs = pygrib.open(grib_file)\n",
    "    \n",
    "    dict_out={}\n",
    "    for key in keys:\n",
    "        vars_values = []\n",
    "        vars_time = []\n",
    "        for grb in grbs:\n",
    "            # Grab the various metadata\n",
    "            if grb.parameterName == key:\n",
    "                vars_time.append(grb.validDate)\n",
    "                vars_values.append((grb.values*grb.scaleValuesBy)+grb.offsetValuesBy)\n",
    "        # Pack into the dictionary\n",
    "        if 'latitude' not in dict_out.keys():\n",
    "            lats,longs = grb.latlons()\n",
    "            lats = lats[:,0]\n",
    "            longs = longs[0,:]\n",
    "            dict_out['latitude']={'values':lats}\n",
    "            dict_out['longitude']={'values':longs}\n",
    "            dict_out['time']={'values':vars_time}\n",
    "        dict_out[key] = {'values':vars_values, 'units':grb.parameterUnits,'missing_values':grb.missingValue, 'standard_name':grb.cfName}    \n",
    "        \n",
    "        return dict_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': {'missing_values': 9999,\n",
       "  'standard_name': 'unknown',\n",
       "  'units': 'm',\n",
       "  'values': []},\n",
       " 'longitude': {'values': array([  0.   ,   1.125,   2.25 ,   3.375,   4.5  ,   5.625,   6.75 ,\n",
       "           7.875,   9.   ,  10.125,  11.25 ,  12.375,  13.5  ,  14.625,\n",
       "          15.75 ,  16.875,  18.   ,  19.125,  20.25 ,  21.375,  22.5  ,\n",
       "          23.625,  24.75 ,  25.875,  27.   ,  28.125,  29.25 ,  30.375,\n",
       "          31.5  ,  32.625,  33.75 ,  34.875,  36.   ,  37.125,  38.25 ,\n",
       "          39.375,  40.5  ,  41.625,  42.75 ,  43.875,  45.   ,  46.125,\n",
       "          47.25 ,  48.375,  49.5  ,  50.625,  51.75 ,  52.875,  54.   ,\n",
       "          55.125,  56.25 ,  57.375,  58.5  ,  59.625,  60.75 ,  61.875,\n",
       "          63.   ,  64.125,  65.25 ,  66.375,  67.5  ,  68.625,  69.75 ,\n",
       "          70.875,  72.   ,  73.125,  74.25 ,  75.375,  76.5  ,  77.625,\n",
       "          78.75 ,  79.875,  81.   ,  82.125,  83.25 ,  84.375,  85.5  ,\n",
       "          86.625,  87.75 ,  88.875,  90.   ,  91.125,  92.25 ,  93.375,\n",
       "          94.5  ,  95.625,  96.75 ,  97.875,  99.   , 100.125, 101.25 ,\n",
       "         102.375, 103.5  , 104.625, 105.75 , 106.875, 108.   , 109.125,\n",
       "         110.25 , 111.375, 112.5  , 113.625, 114.75 , 115.875, 117.   ,\n",
       "         118.125, 119.25 , 120.375, 121.5  , 122.625, 123.75 , 124.875,\n",
       "         126.   , 127.125, 128.25 , 129.375, 130.5  , 131.625, 132.75 ,\n",
       "         133.875, 135.   , 136.125, 137.25 , 138.375, 139.5  , 140.625,\n",
       "         141.75 , 142.875, 144.   , 145.125, 146.25 , 147.375, 148.5  ,\n",
       "         149.625, 150.75 , 151.875, 153.   , 154.125, 155.25 , 156.375,\n",
       "         157.5  , 158.625, 159.75 , 160.875, 162.   , 163.125, 164.25 ,\n",
       "         165.375, 166.5  , 167.625, 168.75 , 169.875, 171.   , 172.125,\n",
       "         173.25 , 174.375, 175.5  , 176.625, 177.75 , 178.875, 180.   ,\n",
       "         181.125, 182.25 , 183.375, 184.5  , 185.625, 186.75 , 187.875,\n",
       "         189.   , 190.125, 191.25 , 192.375, 193.5  , 194.625, 195.75 ,\n",
       "         196.875, 198.   , 199.125, 200.25 , 201.375, 202.5  , 203.625,\n",
       "         204.75 , 205.875, 207.   , 208.125, 209.25 , 210.375, 211.5  ,\n",
       "         212.625, 213.75 , 214.875, 216.   , 217.125, 218.25 , 219.375,\n",
       "         220.5  , 221.625, 222.75 , 223.875, 225.   , 226.125, 227.25 ,\n",
       "         228.375, 229.5  , 230.625, 231.75 , 232.875, 234.   , 235.125,\n",
       "         236.25 , 237.375, 238.5  , 239.625, 240.75 , 241.875, 243.   ,\n",
       "         244.125, 245.25 , 246.375, 247.5  , 248.625, 249.75 , 250.875,\n",
       "         252.   , 253.125, 254.25 , 255.375, 256.5  , 257.625, 258.75 ,\n",
       "         259.875, 261.   , 262.125, 263.25 , 264.375, 265.5  , 266.625,\n",
       "         267.75 , 268.875, 270.   , 271.125, 272.25 , 273.375, 274.5  ,\n",
       "         275.625, 276.75 , 277.875, 279.   , 280.125, 281.25 , 282.375,\n",
       "         283.5  , 284.625, 285.75 , 286.875, 288.   , 289.125, 290.25 ,\n",
       "         291.375, 292.5  , 293.625, 294.75 , 295.875, 297.   , 298.125,\n",
       "         299.25 , 300.375, 301.5  , 302.625, 303.75 , 304.875, 306.   ,\n",
       "         307.125, 308.25 , 309.375, 310.5  , 311.625, 312.75 , 313.875,\n",
       "         315.   , 316.125, 317.25 , 318.375, 319.5  , 320.625, 321.75 ,\n",
       "         322.875, 324.   , 325.125, 326.25 , 327.375, 328.5  , 329.625,\n",
       "         330.75 , 331.875, 333.   , 334.125, 335.25 , 336.375, 337.5  ,\n",
       "         338.625, 339.75 , 340.875, 342.   , 343.125, 344.25 , 345.375,\n",
       "         346.5  , 347.625, 348.75 , 349.875, 351.   , 352.125, 353.25 ,\n",
       "         354.375, 355.5  , 356.625, 357.75 , 358.875])},\n",
       " 'time': {'values': []}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_out =  getGribVar(file,keys)  \n",
    "\n",
    "dict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
